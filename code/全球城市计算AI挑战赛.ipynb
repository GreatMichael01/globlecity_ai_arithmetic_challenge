{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from scipy.stats import norm, rankdata\n",
    "import warnings\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import metrics\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(font_scale=1)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../input'\n",
    "test = pd.read_csv(path + '/Metro_testA/testA_submit_2019-01-29.csv')\n",
    "test_28 = pd.read_csv(path + '/Metro_testA/testA_record_2019-01-28.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1、构造基本特征，主要为时间特征、count、sum等。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_features(df_):\n",
    "    \n",
    "    df = df_.copy()\n",
    "    # base time\n",
    "    df['day'] = df['time'].apply(lambda x: int(x[8:10]))\n",
    "    df['week'] = pd.to_datetime(df['time']).dt.dayofweek + 1\n",
    "    df['weekend'] = (pd.to_datetime(df.time).dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['time'].apply(lambda x: int(x[11:13]))\n",
    "    df['minute'] = df['time'].apply(lambda x: int(x[14:15]+'0'))\n",
    "    \n",
    "    # count,sum\n",
    "    result = df.groupby(['stationID', 'week', 'weekend', 'day', 'hour', 'minute']).status.agg(['count', 'sum']).reset_index()\n",
    "     \n",
    "    # nunique\n",
    "    tmp = df.groupby(['stationID'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID')\n",
    "    result = result.merge(tmp, on=['stationID'], how='left')\n",
    "    tmp = df.groupby(['stationID','hour'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID_hour')\n",
    "    result = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "    tmp = df.groupby(['stationID','hour','minute'])['deviceID'].nunique().\\\n",
    "                                           reset_index(name='nuni_deviceID_of_stationID_hour_minute')\n",
    "    result  = result.merge(tmp, on=['stationID','hour','minute'], how='left')\n",
    "    \n",
    "    # in,out\n",
    "    result['inNums']  = result['sum']\n",
    "    result['outNums'] = result['count'] - result['sum']\n",
    "    \n",
    "    #\n",
    "    result['day_since_first'] = result['day'] - 1 \n",
    "    result.fillna(0, inplace=True)\n",
    "    del result['sum'],result['count']\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_base_features(test_28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2、加载所有文件数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = os.listdir(path+'/Metro_train/')\n",
    "for i in range(0, len(data_list)):\n",
    "    if data_list[i].split('.')[-1] == 'csv':\n",
    "        print(data_list[i], i)\n",
    "        df = pd.read_csv(path+'/Metro_train/' + data_list[i])\n",
    "        df = get_base_features(df)\n",
    "        data = pd.concat([data, df], axis=0, ignore_index=True)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3、由于26和27号数据不存在，故剔除所有周末的数据。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除周末,并修改为连续时间\n",
    "data = data[(data.day!=5)&(data.day!=6)]\n",
    "data = data[(data.day!=12)&(data.day!=13)]\n",
    "data = data[(data.day!=19)&(data.day!=20)]\n",
    "data = data[(data.day!=26)&(data.day!=27)]\n",
    "\n",
    "def fix_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [7,8,9,10,11]:\n",
    "        return d - 2\n",
    "    elif d in [14,15,16,17,18]:\n",
    "        return d - 4\n",
    "    elif d in [21,22,23,24,25]:\n",
    "        return d - 6\n",
    "    elif d in [28]:\n",
    "        return d - 8\n",
    "data['day'] = data['day'].apply(fix_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4、拼接测试集数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['week'] = pd.to_datetime(test['startTime']).dt.dayofweek + 1\n",
    "test['weekend'] = (pd.to_datetime(test.startTime).dt.weekday >=5).astype(int)\n",
    "test['day'] = test['startTime'].apply(lambda x: int(x[8:10]))\n",
    "test['hour'] = test['startTime'].apply(lambda x: int(x[11:13]))\n",
    "test['minute'] = test['startTime'].apply(lambda x: int(x[14:15]+'0'))\n",
    "test['day_since_first'] = test['day'] - 1\n",
    "test = test.drop(['startTime','endTime'], axis=1)\n",
    "data = pd.concat([data,test], axis=0, ignore_index=True)\n",
    "\n",
    "stat_columns = ['inNums','outNums']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5、提取前一天数据作为特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refer_day(d):\n",
    "    if d == 20:\n",
    "        return 29\n",
    "    else:\n",
    "        return d + 1\n",
    "\n",
    "tmp = data.copy()\n",
    "tmp_df = tmp[tmp.day==1]\n",
    "tmp_df['day'] = tmp_df['day'] - 1\n",
    "tmp = pd.concat([tmp, tmp_df], axis=0, ignore_index=True)\n",
    "tmp['day'] = tmp['day'].apply(get_refer_day)\n",
    "\n",
    "for f in stat_columns:\n",
    "    tmp.rename(columns={f: f+'_last'}, inplace=True) \n",
    "    \n",
    "tmp = tmp[['stationID','day','hour','minute','inNums_last','outNums_last']]\n",
    "\n",
    "data = data.merge(tmp, on=['stationID','day','hour','minute'], how='left')\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6、按week,hour,minute分别对inNums和outNums构造统计特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.groupby(['stationID','week','hour','minute'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_whm_max':'max',\n",
    "                                                                        'inNums_whm_min'    : 'min',\n",
    "                                                                        'inNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour','minute'], as_index=False)['outNums'].agg({\n",
    "                                                                        'outNums_whm_max'    : 'max',\n",
    "                                                                        'outNums_whm_min'    : 'min',\n",
    "                                                                        'outNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_wh_max'    : 'max',\n",
    "                                                                        'inNums_wh_min'    : 'min',\n",
    "                                                                        'inNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','week','hour'], as_index=False)['outNums'].agg({\n",
    "                                                                        #'outNums_wh_max'    : 'max',\n",
    "                                                                        #'outNums_wh_min'    : 'min',\n",
    "                                                                        'outNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','week','hour'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7、恢复初始时间**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [5,6,7,8,9]:\n",
    "        return d + 2\n",
    "    elif d in [10,11,12,13,14]:\n",
    "        return d + 4\n",
    "    elif d in [15,16,17,18,19]:\n",
    "        return d + 6\n",
    "    elif d == 20:\n",
    "        return d + 8\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "all_columns = [f for f in data.columns if f not in ['weekend','inNums','outNums']]\n",
    "### all data\n",
    "all_data = data[data.day!=29]\n",
    "all_data['day'] = all_data['day'].apply(recover_day)\n",
    "X_data = all_data[all_columns].values\n",
    "\n",
    "train = data[data.day <20]\n",
    "train['day'] = train['day'].apply(recover_day)\n",
    "X_train = train[all_columns].values\n",
    "\n",
    "valid = data[data.day==20]\n",
    "valid['day'] = valid['day'].apply(recover_day)\n",
    "X_valid = valid[all_columns].values\n",
    "\n",
    "test  = data[data.day==29]\n",
    "X_test = test[all_columns].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8、构建训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_seed':0,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':2\n",
    "}\n",
    "\n",
    "######################################################inNums\n",
    "y_train = train['inNums']\n",
    "y_valid = valid['inNums']\n",
    "y_data  = all_data['inNums']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['inNums'] = gbm.predict(X_test)\n",
    "\n",
    "######################################################outNums\n",
    "y_train = train['outNums']\n",
    "y_valid = valid['outNums']\n",
    "y_data  = all_data['outNums']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['outNums'] = gbm.predict(X_test)\n",
    "\n",
    "sub = pd.read_csv(path + '/Metro_testA/testA_submit_2019-01-29.csv')\n",
    "sub['inNums']   = test['inNums'].values\n",
    "sub['outNums']  = test['outNums'].values\n",
    "# 结果修正\n",
    "sub.loc[sub.inNums<0 , 'inNums']  = 0\n",
    "sub.loc[sub.outNums<0, 'outNums'] = 0\n",
    "sub[['stationID', 'startTime', 'endTime', 'inNums', 'outNums']].to_csv('output/sub_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
