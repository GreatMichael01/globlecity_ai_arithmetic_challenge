{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 本文结合EDA进行规则设计,初赛可以认为是短期时间序列预测,所以越近的数据相关性越强,但很多时候我们又不可避免的遇到奇异值的情况，而奇异值的出现又会大大影响我们的预测, 本篇文章我们采用上周的分钟&小时均值来减小奇异值的影响，针对该问题设计了一种规则, 该规则可以达到LB 12.10, 即初赛top2%的成绩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1  工具包导入&数据读取\n",
    "    * 1.1  工具包导入\n",
    "    * 1.2  数据读取\n",
    "2  EDA\n",
    "    * 2.1  数据准备\n",
    "        * 2.1.1  将数据转化为10分钟的单位\n",
    "        * 2.1.2  获取inNums&outNums\n",
    "    * 2.2  最新一周每条地铁线观测\n",
    "        * 2.2.1  0号站点观察\n",
    "        * 2.2.2  1号站点观察\n",
    "    * 2.3  查看可能带来较大误差的地铁线\n",
    "        * 2.3.1  15号站点观察\n",
    "            * 2.3.1.1  Innums\n",
    "            * 2.3.1.2  Outnums\n",
    "        * 2.3.2  9号站点观察\n",
    "            * 2.3.2.1  Innums\n",
    "            * 2.3.2.2  Outnums\n",
    "3  规则建模\n",
    "    * 3.1  统计10分钟均值特征\n",
    "    * 3.2  统计小时均值特征\n",
    "    * 3.3  计算比例\n",
    "        * 3.3.1  压缩\n",
    "    * 3.4  计算28日小时的均值\n",
    "    * 3.5  预测： 29日的10min中预测结果 = 上周10min中的值 / 对应的小时均值 * 28日的小时均值\n",
    "4  小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  工具包导入&数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1  工具包导入&数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据工具包\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from functools import partial\n",
    "\n",
    "import os \n",
    "import gc\n",
    "from scipy.sparse import vstack  \n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import multiprocessing as mp\n",
    "import seaborn as sns \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2  数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='/data/TC_Underground/'\n",
    "train = pd.DataFrame()\n",
    "for i in tqdm(range(1,26)):\n",
    "    if i < 10:\n",
    "        train_tmp = pd.read_csv(path + 'record_2019-01-0' + str(i) + '.csv')\n",
    "    else:\n",
    "        train_tmp = pd.read_csv(path + 'record_2019-01-' + str(i) + '.csv')\n",
    "    if i== 1:\n",
    "        train = train_tmp\n",
    "    else:\n",
    "        train = pd.concat([train, train_tmp],axis=0,ignore_index=True) \n",
    "\n",
    "test_A_record  = pd.read_csv(path + 'testA_record_2019-01-28.csv')  \n",
    "train  = pd.concat([train, test_A_record],axis=0, ignore_index = True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 好的规则的设计都是基于好的EDA,如果没有很好的EDA,规则是较难设计的,所以此处我们先做EDA,那么在时序问题的时候最简单的EDA该从何做起呢？因为本次的赛题天池只给了20多天的数据,其中还有一些特殊的时间,例如1.1日是元旦期间,那个时候的分布很明显会和其他时间段不一样,不过幸运的是我们只需要预测29日的地铁10分钟流量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1  数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1  将数据转化为10分钟的单位\n",
    "* 此处和需要提交的sub达到类似的形式(以10min为单位)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_time_10_minutes(x):\n",
    "    x_split = x.split(':')\n",
    "    x_part1 = x_split[0]\n",
    "    x_part2 = int(x_split[1]) // 10\n",
    "    if x_part2 == 0:\n",
    "        x_part2 = '00'\n",
    "    else:\n",
    "        x_part2 = str(x_part2 * 10)\n",
    "    return x_part1 + ':' + x_part2 + ':00'\n",
    "     \n",
    "train['startTime'] = train['time'].astype(str).apply(lambda x: trans_time_10_minutes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 时间信息拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train就是1-25号所有统计的记录，按照题目要求作出十分钟级别的dataframe。\n",
    "# 通过画图，我们可以发现，1.21-1.25图形走势高度相似，同时和1.28的整体走势也较为相似。\n",
    "train['days']    = pd.to_datetime(train['startTime'],format='%Y-%m-%d %H:%M:%S').dt.day\n",
    "train['hours']   = pd.to_datetime(train['startTime'],format='%Y-%m-%d %H:%M:%S').dt.hour\n",
    "train['minutes'] = pd.to_datetime(train['startTime'],format='%Y-%m-%d %H:%M:%S').dt.minute\n",
    "train['wkday']   = pd.to_datetime(train['startTime'],format='%Y-%m-%d %H:%M:%S').dt.weekday "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2  获取inNums&outNums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10minutes = train.groupby(['stationID','startTime','wkday','days','hours','minutes'])['status'].sum().to_frame('inNums').reset_index()\n",
    "train_10minutes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10minutes['outNums']  = train.groupby(['stationID','startTime','wkday','days','hours','minutes'])['status'].count().values\n",
    "train_10minutes['outNums']  = train_10minutes['outNums']  - train_10minutes['inNums']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  最新一周每条地铁线观测\n",
    "\n",
    "* 因为有80多条路线,我们的规则设计主要是希望找到相近分布的曲线,而在时序问题中,越近的数据的关联性往往越大,所以我们选取最近的一周的数据进行观测.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1  0号站点观察\n",
    "\n",
    "* 从下面的图中,我们发现工作日的分布基本都是类似的.同时21日和28日的分布是相近的.(因而我们可以从上周的数据中进行规则的设计)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 0)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['inNums'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2  1号站点观察\n",
    "\n",
    "* 和上面的0号站点是一样的,\n",
    "* 下面我们选取有代表的站点进行分析。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 1)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['inNums'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3  查看可能带来较大误差的地铁线\n",
    "\n",
    "* 往往数值越大的出入也是带来误差最大的站点。\n",
    "* 15,9,4,7,10号站点的流量较大,这些站点往往也是我们的误差所在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10minutes.loc[train_10minutes.days.isin([21,22,23,24,25,28])].groupby(['stationID','days'])['inNums'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10minutes.loc[train_10minutes.days.isin([21,22,23,24,25,28])].groupby(['stationID','days'])['outNums'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1  15号站点观察\n",
    "\n",
    "* 15号的站点的分布28和21有些许差别,峰值部分变小了,但是整体分布看上去还是相差不大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 15)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['inNums'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 15)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['outNums'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.1  Innums\n",
    "\n",
    "* 我们单独把21日和28日的曲线拿出来进行观察,发现28日每个时间点的流量是下降的,也就是说29日可能也会下降.(这个时候据说是返程阶段,很多人已经回家了,所以地铁的流量可能会下降)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_10minutes.loc[(train_10minutes.days.isin([21,28]))]\n",
    "tmp.loc[tmp.stationID == 15].pivot_table(index='hours',columns='days',values='inNums').plot(style='o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1.2  Outnums\n",
    "\n",
    "* 很奇怪的是,28日的出站好像很多都比21日的要高一些,但是总体分布还是类似的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_10minutes.loc[(train_10minutes.days.isin([21,28]))]\n",
    "tmp.loc[tmp.stationID == 15].pivot_table(index='hours',columns='days',values='outNums').plot(style='o-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2  9号站点观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 9)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['inNums'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,8])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Count')\n",
    "for day in [21,22,23,24,25,28]:\n",
    "    tmp = train_10minutes.loc[(train_10minutes.days == day) & (train_10minutes.stationID == 9)].copy()\n",
    "    tmp = tmp.sort_values(['stationID','startTime'])\n",
    "    plt.plot(tmp['startTime'],tmp['outNums'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2.1  Innums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_10minutes.loc[(train_10minutes.days.isin([21,28]))]\n",
    "tmp.loc[tmp.stationID == 9].pivot_table(index='hours',columns='days',values='inNums').plot(style='o-') #title='销量',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2.2  Outnums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_10minutes.loc[(train_10minutes.days.isin([21,28]))]\n",
    "tmp.loc[tmp.stationID == 9].pivot_table(index='hours',columns='days',values='outNums').plot(style='o-') #title='销量',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3  规则建模\n",
    "* 从上面的EDA中,我们发现相邻一周的每个站点的分布是类似的,于是我们便可以得到很多简单的规则建模,最容易想到的有:\n",
    "* 基于相邻两天的分布是强相关的特征,我们可以用前一天的预测后一天的,参见林有夕的开源.\n",
    "* 基于相邻一周中周一的分布观测情况,我们假设我们数据的分布存在周期分布,所以我们可以直接用上一周周二(22日)的信息预测29日的结果.\n",
    "* 但是上面两个方法还是有些太简单了,此处我们采用一种平滑的方案."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1  统计10分钟均值特征\n",
    "\n",
    "统计上周每个十分钟段的in和out的均值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一步，我们先做成十分钟的均值/小时级均值，得到每十分钟相对于本小时的比例。因为相对而言，小时级的稳定性更高\n",
    "t21_25 =train_10minutes[(train_10minutes['days']>=21)&(train_10minutes['days']<=25)]\n",
    "t21_25_in = t21_25.groupby(['stationID', 'hours', 'minutes'])['inNums'].agg({'in_mean':'mean'}).reset_index()\n",
    "t21_25_out =t21_25.groupby(['stationID', 'hours', 'minutes'])['outNums'].agg({'out_mean':'mean'}).reset_index()\n",
    "t21_25_in_out = t21_25_in.merge(t21_25_out,on = ['stationID', 'hours', 'minutes'],how = 'left')\n",
    "t21_25_in_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2  统计小时均值特征\n",
    "\n",
    "统计上周每小时时段的in和out的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t21_25_in_hour = t21_25.groupby(['stationID', 'hours'])['inNums'].agg({'in_mean_hour':'mean'}).reset_index()\n",
    "t21_25_out_hour = t21_25.groupby(['stationID', 'hours'])['outNums'].agg({'out_mean_hour':'mean'}).reset_index()\n",
    "t21_25_in_out_hour = t21_25_in_hour.merge(t21_25_out_hour,on = ['stationID', 'hours'],how = 'left')\n",
    "t21_25_in_out_hour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3  计算比例\n",
    "\n",
    "计算每十分钟占该小时的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t21_25_in_out = t21_25_in_out.merge(t21_25_in_out_hour,on = ['stationID', 'hours'],how = 'left')\n",
    "t21_25_in_out['in_bili'] = t21_25_in_out['in_mean'] / (t21_25_in_out['in_mean_hour']+0.001)\n",
    "t21_25_in_out['out_bili'] = t21_25_in_out['out_mean']/ (t21_25_in_out['out_mean_hour']+0.001)\n",
    "t21_25_in_out_bili = t21_25_in_out[['stationID', 'hours', 'minutes','in_bili','out_bili']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1  压缩\n",
    "\n",
    "* 有的时候可能会出现某一天突发情况,会出现某一时刻值特别大,那这个时候可能需要控制一下,此处我们对6点前这种情况进行压缩,如果某一天除以均值大于2,那么我们将其压缩至2.\n",
    "* 凌晨时候，由于有地铁员工刷卡进站，其实人流量极少，在做比例的时候，可能会被突然放大，本身loss是mae，这种极小值没不要在乎，直接压缩他们的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要加一个function判断，把小于6点的记录，大于2的都强制压倒2以内。我忘记咋写了，丢在家里了。因为之前除数里面有0.001，有可能会突然偏大。改好了！\n",
    "def function(a, b):\n",
    "    if a>=2 and b <=6: \n",
    "        return 2\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "t21_25_in_out_bili['in_bili']  = t21_25_in_out_bili.apply(lambda x: function(x.in_bili, x.hours), axis = 1)\n",
    "t21_25_in_out_bili['out_bili'] = t21_25_in_out_bili.apply(lambda x: function(x.out_bili, x.hours), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4  计算28日小时的均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本规则的主要思想，就是利用相似性，预测目标的1.29，而时序问题是短期相似的，那么1.28和1.29的之间更为相似。\n",
    "# 获取28号记录\n",
    "t28 = train_10minutes[(train_10minutes['days']==28)]\n",
    "\n",
    "# 把28号记录转化成小时级，因为28的十分钟级存在一定程度的随机性，而相对而言，小时级的稳定性更高\n",
    "\n",
    "t28_in_hour = t28.groupby(['stationID', 'hours'])['inNums'].agg({'in28_mean_hour':'mean'}).reset_index()\n",
    "t28_out_hour = t28.groupby(['stationID', 'hours'])['outNums'].agg({'out28_mean_hour':'mean'}).reset_index()\n",
    "t28_in_out_hour = t28_in_hour.merge(t28_out_hour,on = ['stationID', 'hours'],how = 'left')\n",
    "\n",
    "t28 = t28.merge(t28_in_out_hour,on = ['stationID', 'hours'],how = 'left')\n",
    "t_28 = t28[['stationID', 'hours', 'minutes','inNums','outNums','in28_mean_hour','out28_mean_hour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5  预测： 29日的10min中预测结果 = 上周10min中的值 / 对应的小时均值 * 28日的小时均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub29=pd.read_csv(path + 'testA_submit_2019-01-29.csv')\n",
    "del sub29['inNums']\n",
    "del sub29['outNums']\n",
    "\n",
    "sub29['hours']  = pd.to_datetime(sub29['startTime'],format='%Y-%m-%d %H:%M:%S').dt.hour\n",
    "sub29['minutes']= pd.to_datetime(sub29['startTime'],format='%Y-%m-%d %H:%M:%S').dt.minute\n",
    "\n",
    "sub29=sub29.merge(t21_25_in_out_bili,on = ['stationID', 'hours', 'minutes'],how = 'left')\n",
    "sub29=sub29.merge(t_28,on = ['stationID', 'hours', 'minutes'],how = 'left')\n",
    "sub29=sub29.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 此处乘以0.95是考虑到春运,人口会迅速下降，所以我们假设周二的总量小于周一的总量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub29['in29'] = sub29['in_bili'] * sub29['in28_mean_hour']*0.95\n",
    "sub29['out29']= sub29['out_bili']* sub29['out28_mean_hour']*0.95\n",
    "\n",
    "submition=sub29[['stationID','startTime','endTime','in29','out29']]\n",
    "submition=submition.rename(columns = {'in29':'inNums'})\n",
    "submition=submition.rename(columns = {'out29':'outNums'})\n",
    "submition.to_csv('baseline.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4  小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一小节,通过EDA发现本周一和上周一的分布类似,同时上周一到上周五的分布都是类似的,为了防止极值带来的影响,我们对小时和分钟取均值,然后计算比例, 然后用28日的小时均值近似本周的小时均值,乘以上一周的比例,从而得到29日的预测结果。\n",
    "\n",
    "最后乘以0.95是假设周二的总量小于周一的总量(考虑到春运,人口会迅速下降), 通过上面的操作我们可以得到A榜12.10左右的分数。大概是58名的成绩。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
